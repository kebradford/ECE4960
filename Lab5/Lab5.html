<!DOCTYPE html>
  <html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    <title>Lab 5</title>
    <style>
      body{
        padding: 0 80px;}
    </style>
</head>
  <body>
    <div id= "header">
      <center><h1> Lab 5 - Obstacle Avoidance</h1></center>
    </div>
    <div id = "navbar">
      <a href="https://kebradford.github.io/ECE4960"><button class="btn"><i class="fa fa-home"></i> Back to Home Page</button></a>
    </div>
    <br>
    <br>
    <center><h2>Objective </h2></center>
    
      <p>Perform obstacle avoidance with the physical robot using TOF and proximity sensors, on the virtual robot using laser range finder</p>
      <br>
    <br>
    <center><h2>Materials Used</h2></center>
       <ul>
         <li>1 RC Car</li>
         <li>1 Artemis Nano</li>
         <li>1 USB A/C Cable</li>
         <li>2 batteries (car battery, board battery)</li>
         <li>1 Sparkfun motor driver</li>
         <li>3 Qwiic connectors</li>
         <li>2 screwdrivers (flathead and phillips)</li>
         <li>1 wire stripper/cutter</li>
         <li>1 TOF sensor</li>
         <li>1 proximity sensor</li>
       </ul>
    <br>
    <br>


    <center><h2>Procedure</h2></center>
    <p>
      <h3>5A: Obstacle Avoidance on Physical Robot</h3>
      <br><br>
      First, in order to perform obstacle avoidance on the physical robot, I had to parameterize the two sensors: the proximity sensor and the TOF sensor. 
      <br><br>
      <h5>Proximity Sensor</h5>

      <br><br>
      The proximity sensor used was the SparkFun VCNL4040 Proximity Sensor. First, I set up the Arduino library, hooked up the sensor via Qwicc connect to the Artemis Nano, and used the example Wire.c to scan the i2c bus for the sensor. 
      <br>
      <img src="i2c1.PNG" alt="i2c1" width="320" height="240">
      <br>

      After that, I used the example code in the library AllReadings to map the sensor readings to actual distances. I used 4 objects: 
      <ul>
         <li>1 Brown Box</li>
         <li>1 Box with White Paper taped to it</li>
         <li>1 red Sparkfun box</li>
         <li>1 black PCB </li>
       </ul>

      <br>
      <img src="brown_box.jpg" alt="brown_box" width="320" height="240"><img src="red_box.jpg" alt="red_box" width="320" height="240">
      <br>

       Noteably, these objects were different colors but also different sizes. The white and brown objects were much larger than the red and brown, and therefore likely blocked out more light. I took measurements with the sensors at several distances to collect meaningful data about the values the sensor would report. 

      


      <br>
      <img src="ambient_light.PNG" alt="ambient_light" width="320" height="240"><img src="white_level.PNG" alt="white_level" width="320" height="240">
      <br>




      <br><br>
      <h5>Time of Flight Sensor</h5>
      <br><br>

      <br>
      <img src="i2c2.PNG" alt="i2c2" width="320" height="240">
      <br>


      <br><br>
      <h3>5B: Obstacle Avoidance in Simulation</h3>
      <br><br>

      <br>
      <video width="320" height="240" controls>
      <source src="obstacle_avoidance.mp4" type="video/mp4">
      </video>
      <br>


    </p>
    <br>
    
  
 
   <a href="#header"><button class="btn"><i class="fa fa-arrow-up"></i>Return to top</button></a>
   </body>
</html>
