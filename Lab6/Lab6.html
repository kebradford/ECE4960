<!DOCTYPE html>
  <html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    <title>Lab 6</title>
    <style>
      body{
        padding: 0 80px;}
    </style>
</head>
  <body>
    <div id= "header">
      <center><h1> Lab 6 - PID Control</h1></center>
    </div>
    <div id = "navbar">
      <a href="https://kebradford.github.io/ECE4960"><button class="btn"><i class="fa fa-home"></i> Back to Home Page</button></a>
    </div>
    <br>
    <br>
    <center><h2>Objective </h2></center>
    
      <p>Get PID control working with IMU</p>
      <br>
    <br>
    <center><h2>Materials Used</h2></center>
       <ul>
         <li>1 RC Car</li>
         <li>1 Artemis Nano</li>
         <li>1 USB A/C Cable</li>
         <li>2 batteries (car battery, board battery)</li>
         <li>1 Sparkfun motor driver</li>
         <li>3 Qwiic connectors</li>
         <li>2 screwdrivers (flathead and phillips)</li>
         <li>1 wire stripper/cutter</li>
         <li>1 TOF sensor</li>
         <li>1 IMU</li>
       </ul>
    <br>
    <br>


    <center><h2>Procedure</h2></center>
    <p>

      <br>
      <h4>Setting up IMU</h4>
      <br>
      First, I hooked up the IMU to the Artemis board via Qwic connector and used the wire code to scan the i2c bus. I found the sensor at 0x69 as expected. 
      <br>
      <img src="i2c.PNG" alt="i2c">
      <br>
      Playing around with the IMU on my desk, I found that the acceleration data generally hovered around (0, 0, 1000) when laying flat, which is expected for 0 acceleration in the x and y directions and 1g of acceleration in the z direction due to gravity. The magnetometer and gyroscope data hovered around zero as well, again expected as the IMU was not moving. 
      <br>
      <img src="IMU_still.PNG" alt="imu still">
      <br>
      When I started waving the IMU around, I got more erratic data reads from all sensors on the 9 DOF IMU. Acceleration data in particular was much higher. 
      <br>
      <img src="IMU_notstill.PNG" alt="imu not still">
      <br>
      <br>
      <h4>Testing the Accelerometer</h4>
      <br>

      First, I read out just the raw data from the accelerometer and plotted it using the Arduino Serial Plotter. Holding it at {-90, 0, 90}, these were the results 

      <br>
      <img src="unfiltered_pitchroll.PNG" alt="imu not still" width="320" height="240">
      <br>

      I saw that there was a lot of noise on it, so I did some analysis of the accelerometer X data while lying flat on the table. I found an average value of .205 with a stdev of .4, which I did not find unreasonbly uncalibrated for the sensor. An average value of .2 could correspond with my table not being exactly flat. 
      <br>
      <img src="accnoise.PNG" alt="imu not still" width="320" height="240">
      <br>
      I next tried tapping at the table while the IMU was sitting still. I found large spikes when this happened. 
      <br>
      <img src="tap_imu.PNG" alt="imu not still" width="320" height="240">
      <br>
      So I plotted the FFT in python to see the frequencies of the disturbances. 
      <br>
      <img src="frequency_response.PNG" alt="imu not still" width="320" height="240">
      <br>
      The highest frequency response I observed was at 200 Hz. Using the equations from class to calculate alpha, I set RC to 200 Hz and T to 1/(30ms) (the delay time) to achieve an alpha of .14. I tested this functionality by setting up a rolling filter and seeing the response. I tilted the IMU by 90 degrees and observed the change, which was very smooth after the filter was implemented, and not spiky like before. 

      <code><pre>

    pitch_a = atan2(myICM.accX(), myICM.accZ())*180/M_PI;
    roll_a  = atan2(myICM.accY(), myICM.accZ())*180/M_PI;

    alpha = .14;
    pitch_alpha = (alpha*pitch_a)+((1-alpha)*old_pitch);
    old_pitch = pitch_alpha;
    roll_alpha = (alpha*roll_a)+((1-alpha)*old_roll);
    old_roll = roll_alpha;


      </pre></code>

      <br>
      <br>


      <br>
      <img src="nice_change.PNG" alt="imu not still" width="320" height="240">
      <br>


    <h4>Setting up Gyro</h4>
    <br>
    Next, I computed the pitch, yaw and roll with the gyro using simple accumulator functions.

    <code><pre>
    pitch_g = pitch_g - myICM.gyrY()*dt; 
    roll_g = roll_g + myICM.gyrX()*dt; 
    yaw_g = yaw_g+myICM.gyrZ()*dt;
    </pre></code>

    I compared the filtered accelerometer data to the gyro data to see how they differ with roll and pitch. 

    <br>
    <img src="rollCompare.PNG" alt="imu not still" width="320" height="240"><img src="pitchCompare.PNG" alt="imu not still" width="320" height="240">
    <br>

    As expected, the gyro data drifts over time but has very smooth and apparently accurate readings relative to previous readings (the drift makes it overall inaccurate). The gyro was also faster to respond due to the filtering happening on the accelerometer. 
    <br>
    Changing the time delay between calls didn't have a huge effect on the accuracy of the reading, but did have a huge effect on how quickly the gyro drifted from center. It was much faster to drift with lower time step, and vice versa. Left image is the slow reading, right is fast
    <br>
    <img src="roll_slow.PNG" alt="imu not still" width="320" height="240"><img src="roll_fast.PNG" alt="imu not still" width="320" height="240">
    <br>

    <br><br>
    Next, I implemented a complimentary filter to fuse the readings from the accelerometer and the gyro using the rolling filter suggested in class to get a more accurate and smooth reading. The filter helped negate the drift from the gyro, while also responding quickly and without extreme sensitivity from the accelerometer. I chose a higher value of beta than used in class to trust the accelerometer slightly more after some trial and error. 
    <br>
    <img src="pitch_combo.PNG" alt="imu not still" width="320" height="240">
    <br>

    <code><pre>
    beta = .15; 
    pitch_combo = (pitch_combo-myICM.gyrY()*dt)*(1-beta)+pitch_alpha*beta;
    </pre></code>

    <br>
    <h4>Setting up Magnetometer</h4>
    <br>
    <br>

    Finally, I took readings from the magnetometer to acquire yaw. I found that the magnetometer was very innacurate and did not respond well to rotation, only reporting around 30 degrees regardless of which angles I was reading. 

    <code><pre>
    yaw_mag = atan2((myICM.magX()*cos(pitch_combo) + myICM.magZ()*sin(pitch_combo)), (myICM.magY()*cos(roll_combo) + myICM.magZ()*sin(roll_combo)));
    </pre></code>

    I determined that the magnetometer would be even worse once mounted to the robot due to noise from the DC motors, and determined that I could instead determine yaw from the gyroscope as Kirstin suggested on CampusWire. The gyro reported a good relative yaw, still drifting but able to respond quickly and robustly to changes in yaw. 

    <br>
    <img src="gyro_yaw.PNG" alt="imu not still" width="320" height="240">
    <br>
      <video width="320" height="240" controls>
      <source src="gyro_yaw.mp4" type="video/mp4">
      </video>
    <br>
    <br>
    <br>
    <br>

    <h2>PID Control</h2>
    <br>
    <br>
    <br>
    First, I tested to see how the robot could reliably spin on its own axis but ramping up and ramping down the speed as the wheels spun in opposite directions. I stopped the ramp up at 200 motor speed, because I found the robot was quickly spinning at this time and I didn't need to go higher for this data. The robot wouldn't start turning at all before around 150, and wouldn't start consistently spinning with both wheels until 190. The ramp down was much smoother than the ramp up, likely due to the different between static and rolling friction constants on the table. There was no difference between the two different wheels in this case, and they both stopped spinning around 154. 

    <code><pre>
        for (int i = 0; i <=motorSpeedMax; i+=1){}
      myICM.getAGMT(); 
        myMotorDriver.setDrive( 1, dirMotors, i); 
        myMotorDriver.setDrive( 0, dirMotors, i);

        dt = (millis()-lastRead)/1000;
        lastRead = millis();
        yaw_g = yaw_g+myICM.gyrZ()*dt; 
        Serial.print("motorSpeed:");
        Serial.print(i);
        Serial.print(" ");
        Serial.print("yaw:");
        Serial.println(yaw_g);
        
        delay(100);
    }
    for (int i = motorSpeedMax; i>=0; i-=1){
      myICM.getAGMT(); 
        myMotorDriver.setDrive( 1, dirMotors, i); 
        myMotorDriver.setDrive( 0, dirMotors, i);

        dt = (millis()-lastRead)/1000;
        lastRead = millis();
        yaw_g = yaw_g+myICM.gyrZ()*dt;
        Serial.print("motorSpeed:");
        Serial.print(i);
        Serial.print(" ");
        Serial.print("yaw:");
        Serial.println(yaw_g);
        dt = (millis()-lastRead)/1000;
        lastRead = millis();
        delay(100);
    }
    </pre></code>



    <br>
    <img src="ramp_up.PNG" alt="imu not still" width="320" height="240">
    <br>

    <br>
    Next, I tested to see how slowly I could consistently spin the robot by simply feeding the motors a constant value. I found that I was able to do this around 180. The robot is a little jerky and sometimes requires a push to get started and get over that static friction, but these are just things to be improved with PID control. 

    <br>
      <video width="320" height="240" controls>
      <source src="spinning_slowly.mp4" type="video/mp4">
      </video>
    <br>

    <br>
    <img src="yaw_rate.PNG"  width="320" height="240">
    <br>

    As seen in the above figure, the slowest I could rotate was around 155 degrees per second. Given the TOF has a minimum reading time of 20ms, the robot would rotate 3 degrees each reading. If the robot was initially .5m from the wall, after a 3 degree rotation it would be .5m/cos(3) = .500686 meters away from the wall for a delta of .686 mm. However, if the robot started at a 45 degree angle, the initial TOF reading would be .7071m, and the reading after an extra 3 degrees of rotation would be .7472m for a delta of 40mm. 





















    <center><h2>Simulation</h2></center>
    <br> 
    To test the simulation, I downloaded lab6 code and ran the simulator. I opened the Jupyter notebook and started playing around with the odometer vs ground truth data 

    <code><pre>
    odom_pos = robot.get_pose() 
    gt_pos   = robot.get_gt_pose()
    print(odom_pose)
    print(gt_pose)
    </pre></code>
    This would show to a fairly high number of sigfigs the position of the robot, which I tested by dragging it around with my mouse and rerunning. After satisying myself with that, I opened up the plotter ("B, S"). I simply pass the x and y values of the get_pose() functions to the plotter to see how close they are. 
    <br>
    I chose a delay time of .03 to match the 30ms in the Arduino code to make this sim more useful to consider for the lab. 

    <br>
    <img src="sim_code.PNG" alt="imu not still">
    <br>


    <br><br>
    I first ran the code while the robot was stationary for as long as it took to start typing this section up, and it drifted quite a bit. This was approximately 3-4 minutes, plotting every .03 seconds, so about 7k points. It gets pretty dense. 

    <br>
    <img src="stationary_sim.PNG" alt="imu not still" width="320" height="240">
    <br>

    Running the sim at several different speeds produced differences in the accuracy of the odometry vs the ground truth. Faster was definitely better, though I am unsure why. I guess that is a good sign for my fast robot! It is possible that the innacuracy has a threshhold, and is less noticeable for larger changes (ie is not proportional to the size of the change in data) Below are three example speeds at .05, .5, and 1 linear speed, respectively. Oddly enough, the odometry was mirrored to the ground truth data, as shown below. 
    <br>
    <img src="speed05.PNG" width="320" height="240"><img src="sim_point5.PNG" width="320" height="240"><img src="sim_one.PNG" width="320" height="240">
    <br>

    I ended up changing the delay time to .3 seconds (ten times slower) because the jupyter notebook was getting kind of laggy. Here are some example speeds and corresponding odometry and ground truth data. Again, the data is oddly mirrored, which could be fixed in code. 
    <br>
      <video width="320" height="240" controls>
      <source src="sim.mp4" type="video/mp4">
      </video>
      <br>

    </p>
    <br>
    
  
 
   <a href="#header"><button class="btn"><i class="fa fa-arrow-up"></i>Return to top</button></a>
   </body>
</html>
